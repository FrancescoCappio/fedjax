{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXAJBz_5kbJW"
      },
      "source": [
        "\n",
        "[Open In Colab](https://colab.research.google.com/github/google/fedjax/blob/main/experimental/notebooks/emnist_compression.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRWNysIeLUEX"
      },
      "outputs": [],
      "source": [
        "import fedjax\n",
        "import jax\n",
        "from jax import jit\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from typing import Any, NamedTuple\n",
        "\n",
        "from fedjax.experimental.aggregators import compression\n",
        "\n",
        "fedjax.training.set_tf_cpu_only()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqYuFksOTnm"
      },
      "source": [
        "```\n",
        "# To disable jit, use 'with jax.disable_jit():'\n",
        "# For example,\n",
        "@jax.jit\n",
        "def f(x):\n",
        "  print(x)\n",
        "  return jnp.sum(x)\n",
        "\n",
        "x = jnp.ones([])\n",
        "\n",
        "print('jit enabled')\n",
        "for _ in range(10):\n",
        "  f(x)\n",
        "\n",
        "print('jit disabled')\n",
        "with jax.disable_jit():\n",
        "  for _ in range(10):\n",
        "    f(x)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 298
        },
        "executionInfo": {
          "elapsed": 11262,
          "status": "ok",
          "timestamp": 1619116468303,
          "user": {
            "displayName": "Ananda Theertha Suresh",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg4ASQTNeiZMOUYQV5omqHOEMPHCXIdMIakUjAUaA=s64",
            "userId": "18398203347691939060"
          },
          "user_tz": 240
        },
        "id": "kp-iACjELyob",
        "outputId": "5d94a2f2-9314-4d88-da7e-a0aaa4e36bc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cmatplotlib.image.AxesImage at 0x7f670e2be2e8\u003e"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nE8YuNWHsUhP/B/Bw1fBBckbEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cFigure size 600x400 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the model and the data.\n",
        "model = fedjax.models.emnist.create_conv_model(only_digits=False)\n",
        "train, test = fedjax.datasets.emnist.load_data(only_digits=False,\n",
        "                                               cache_dir='/tmp/emnist_data')\n",
        "# Print a single client data to verify data is loaded.\n",
        "example_client_id = 'f0000_14'\n",
        "single_client_data = train.create_tf_dataset_for_client(example_client_id)\n",
        "numpy_client_data = list(single_client_data.as_numpy_iterator())\n",
        "pixels = numpy_client_data[0]['x']\n",
        "label = numpy_client_data[0]['y']\n",
        "plt.title(f'{label}')\n",
        "plt.imshow(pixels.reshape(28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s30qnrML6t9"
      },
      "outputs": [],
      "source": [
        "# Define federated algorithm.\n",
        "\n",
        "\n",
        "Model = fedjax.Model\n",
        "Params = fedjax.Params\n",
        "OptState = fedjax.OptState\n",
        "Optimizer = fedjax.Optimizer\n",
        "\n",
        "class FedAvgServerState(NamedTuple):\n",
        "  params: Params\n",
        "  opt_state: OptState\n",
        "  aggregator_state: Any\n",
        "\n",
        "class SimpleFedAvg():\n",
        "\n",
        "  def __init__(self,\n",
        "               model: Model,\n",
        "               client_optimizer: Optimizer,\n",
        "               server_optimizer: Optimizer,\n",
        "               client_batch_size: int,\n",
        "               num_levels: int):\n",
        "    self.model = model\n",
        "    self.client_optimizer = client_optimizer\n",
        "    self.server_optimizer = server_optimizer\n",
        "    self.client_batch_size = client_batch_size\n",
        "    self.aggregator = compression.uniform_stochastic_quantizer(\n",
        "        num_levels=num_levels)\n",
        "    \n",
        "  \n",
        "  def client_update(self, server_state, client_data):\n",
        "    params = server_state.params\n",
        "    opt_state = self.client_optimizer.init_fn(params)\n",
        "    num_examples = 0.\n",
        "    rng_seq = fedjax.PRNGSequence(0)\n",
        "    for batch, rng in zip(client_data, rng_seq):\n",
        "      backward_pass_output = self.model.backward_pass(params, batch, rng)\n",
        "      grads = backward_pass_output.grads\n",
        "      updates, opt_state = self.client_optimizer.update_fn(grads, opt_state)\n",
        "      params = self.client_optimizer.apply_updates(updates, params)\n",
        "      num_examples += backward_pass_output.num_examples\n",
        "    delta = jax.tree_util.tree_multimap(lambda a, b: a - b, \n",
        "                                        server_state.params,\n",
        "                                        params)\n",
        "    return delta, num_examples\n",
        "\n",
        "  def server_update(self, server_state, client_outputs):\n",
        "    rng_seq = fedjax.PRNGSequence(0)\n",
        "    weighted_averaged_delta, new_aggregator_state = self.aggregator.apply(\n",
        "        client_outputs, rng_seq, server_state.aggregator_state)\n",
        "    updates, opt_state = server_optimizer.update_fn(weighted_averaged_delta,\n",
        "                                                    server_state.opt_state)\n",
        "    params = server_optimizer.apply_updates(updates, server_state.params)\n",
        "    return FedAvgServerState(params, opt_state, new_aggregator_state)\n",
        "\n",
        "  def init(self, rng):\n",
        "    params = model.init_params(rng)\n",
        "    opt_state = self.server_optimizer.init_fn(params)\n",
        "    aggregator_state = self.aggregator.init()\n",
        "    return FedAvgServerState(params, opt_state, aggregator_state)\n",
        "\n",
        "  def run_one_round(self, server_state, client_ids):\n",
        "    client_outputs = []\n",
        "    for client_id in client_ids:\n",
        "      client_data = train.create_tf_dataset_for_client(client_id)\n",
        "      client_data = client_data.batch(self.client_batch_size)\n",
        "      client_data = client_data.as_numpy_iterator()\n",
        "      client_outputs.append(self.client_update(server_state, client_data))\n",
        "    return self.server_update(server_state, client_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1383979,
          "status": "ok",
          "timestamp": 1619127658066,
          "user": {
            "displayName": "Ananda Theertha Suresh",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg4ASQTNeiZMOUYQV5omqHOEMPHCXIdMIakUjAUaA=s64",
            "userId": "18398203347691939060"
          },
          "user_tz": 240
        },
        "id": "O5IHdAjEjOan",
        "outputId": "37eedc27-19c2-4756-aaf6-fb03b3141ea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round_num: 25, mean_round_duration: 1.525042886734009 sec\n",
            "round_num: 50, mean_round_duration: 1.3385536766052246 sec\n",
            "round_num: 75, mean_round_duration: 1.3813207530975342 sec\n",
            "round_num: 100, mean_round_duration: 1.3918876075744628 sec\n",
            "round_num: 125, mean_round_duration: 1.556784725189209 sec\n",
            "round_num: 150, mean_round_duration: 1.4496421813964844 sec\n",
            "round_num: 175, mean_round_duration: 1.5728481101989746 sec\n",
            "round_num: 200, mean_round_duration: 1.3059182453155518 sec\n",
            "round_num: 225, mean_round_duration: 1.3199282741546632 sec\n",
            "round_num: 250, mean_round_duration: 1.3994597625732421 sec\n",
            "round_num: 275, mean_round_duration: 1.3082616424560547 sec\n",
            "round_num: 300, mean_round_duration: 1.4410183334350586 sec\n",
            "round_num: 325, mean_round_duration: 1.3942552280426026 sec\n",
            "round_num: 350, mean_round_duration: 1.377430238723755 sec\n",
            "round_num: 375, mean_round_duration: 1.5493021869659425 sec\n",
            "round_num: 400, mean_round_duration: 1.4330929279327393 sec\n",
            "round_num: 425, mean_round_duration: 1.3457640266418458 sec\n",
            "round_num: 450, mean_round_duration: 1.3755673694610595 sec\n",
            "round_num: 475, mean_round_duration: 1.3139009761810303 sec\n",
            "round_num: 500, mean_round_duration: 1.5420234298706055 sec\n",
            "round_num: 525, mean_round_duration: 1.4010581493377685 sec\n",
            "round_num: 550, mean_round_duration: 1.3134736156463622 sec\n",
            "round_num: 575, mean_round_duration: 1.328404130935669 sec\n",
            "round_num: 600, mean_round_duration: 1.3582437229156494 sec\n",
            "round_num: 625, mean_round_duration: 1.4653415203094482 sec\n",
            "round_num: 650, mean_round_duration: 1.336175832748413 sec\n",
            "round_num: 675, mean_round_duration: 1.258411512374878 sec\n",
            "round_num: 700, mean_round_duration: 1.3750392055511476 sec\n",
            "round_num: 725, mean_round_duration: 1.453853235244751 sec\n",
            "round_num: 750, mean_round_duration: 1.28388503074646 sec\n",
            "round_num: 775, mean_round_duration: 1.2825447845458984 sec\n",
            "round_num: 800, mean_round_duration: 1.249696226119995 sec\n",
            "round_num: 825, mean_round_duration: 1.3202034664154052 sec\n",
            "round_num: 850, mean_round_duration: 1.4224749946594237 sec\n",
            "round_num: 875, mean_round_duration: 1.2367712211608888 sec\n",
            "round_num: 900, mean_round_duration: 1.3851833820343018 sec\n",
            "round_num: 925, mean_round_duration: 1.2732955265045165 sec\n",
            "round_num: 950, mean_round_duration: 1.3939816284179687 sec\n",
            "round_num: 975, mean_round_duration: 1.5427883911132811 sec\n",
            "round_num: 1000, mean_round_duration: 1.3470980834960937 sec\n"
          ]
        }
      ],
      "source": [
        "# Run federated algorithm.\n",
        "# The hyper-parameters here is not the state of the art. It achieves a\n",
        "# global test accuracy as follows\n",
        "# num_levels, server_learning_rate, test_accuracy \n",
        "# 256, 1.0, 84.5%\n",
        "# 16, 0.01, 59.8%\n",
        "# 2, 0.001, 23.6%\n",
        "num_rounds = 1000\n",
        "num_clients_per_round = 10\n",
        "rng = 0\n",
        "client_batch_size = 10\n",
        "# num_levels is the number levels of quantization. The number of bits\n",
        "# used is log_2(num_levels).\n",
        "num_levels = 2\n",
        "client_optimizer = fedjax.get_optimizer(fedjax.OptimizerName.SGD,\n",
        "                                        learning_rate=0.1)\n",
        "server_optimizer = fedjax.get_optimizer(fedjax.OptimizerName.SGD,\n",
        "                                        learning_rate=0.001)\n",
        "\n",
        "algorithm = SimpleFedAvg(model, client_optimizer,\n",
        "                         server_optimizer, client_batch_size, num_levels)\n",
        "start = time.time()\n",
        "server_state = algorithm.init(rng)\n",
        "np.random.seed(0)\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "  client_ids = np.random.choice(train.client_ids, \n",
        "                                size=num_clients_per_round,\n",
        "                                replace=False)\n",
        "  server_state = algorithm.run_one_round(server_state, client_ids)\n",
        "  if round_num % 25 == 0:\n",
        "    print('round_num: {}, mean_round_duration: {} sec'.format(\n",
        "        round_num, (time.time() - start)/25))\n",
        "    start = time.time() \n",
        "global_params = server_state.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 95397,
          "status": "ok",
          "timestamp": 1619127753549,
          "user": {
            "displayName": "Ananda Theertha Suresh",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg4ASQTNeiZMOUYQV5omqHOEMPHCXIdMIakUjAUaA=s64",
            "userId": "18398203347691939060"
          },
          "user_tz": 240
        },
        "id": "9kUWONxJo7ie",
        "outputId": "8b602cfd-30a8-483d-8591-255017b20d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss             3.879802\n",
            "regularizer      0.000000\n",
            "num_examples    22.789118\n",
            "accuracy         0.236352\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the global model\n",
        "hparams = fedjax.ClientDataHParams(batch_size=10, num_epochs=1) \n",
        "all_metrics = fedjax.evaluate_multiple_clients(federated_data=test, \n",
        "                                               client_ids=test.client_ids,\n",
        "                                               model=model,\n",
        "                                               params=global_params,\n",
        "                                               client_data_hparams=hparams)\n",
        "all_metrics = list(all_metrics)\n",
        "print(pd.DataFrame.from_records(all_metrics).mean())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "emnist-compression.ipynb",
      "provenance": [
        {
          "file_id": "1d3YXAA7t9NFgWFp6YyUNiDHRAGbCaIwq",
          "timestamp": 1619130258104
        },
        {
          "file_id": "1UhglgvY6rQOPGQQPIL7aJRQ5wXndCrWt",
          "timestamp": 1617290897629
        },
        {
          "file_id": "1p7KiuZnXC3KOeJW_ArP-cTzpax0IBBFZ",
          "timestamp": 1616023981580
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
