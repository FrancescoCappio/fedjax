{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVlzn5lPxReI"
      },
      "source": [
        "# FedJAX Datasets\n",
        "\n",
        "This tutorial introduces datasets in FedJAX and how to work with them. By completing this tutorial, you'll learn how to write clear and efficient code when working with datasets that follows best practices.\n",
        "\n",
        "**NOTE: For datasets, everything is done with NumPy NOT JAX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XANytMDXZbAH"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import itertools\n",
        "import fedjax\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnfi9sx6zC6E"
      },
      "source": [
        "## What are datasets in federated learning?\n",
        "\n",
        "In the context of federated learning (FL), data is decentralized across clients, with each client having their own local set of examples. In light of this, we refer to two levels of organization for datasets:\n",
        "\n",
        "- Federated dataset: A collection of clients, each with their own local datasets and metadata\n",
        "- Client dataset: The set of local examples for a particular client\n",
        "\n",
        "You can think of federated data as a mapping from client ids to client datasets and client datasets as a list of examples.\n",
        "\n",
        "```\n",
        "federated_data = {\n",
        "  'client0': ['a', 'b', 'c'],\n",
        "  'client1': ['d', 'e'],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qttyzji6-LU"
      },
      "source": [
        "### Federated datasets structure\n",
        "\n",
        "FedJAX defines a `fedjax.FederatedData` interface for all federated datasets. \n",
        "\n",
        "FedJAX comes packaged with multiple federated datasets, but we will look specifically at the Shakespeare dataset. The Shakespeare dataset is based on [The Complete Works of Shakespeare](https://www.gutenberg.org/files/100/100-0.txt), where each character in the play is a \"client\" and their dialogue lines are the examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxeEfaKb3J9N"
      },
      "outputs": [],
      "source": [
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vt7LCVV_TZl"
      },
      "source": [
        "`train_fd` and `test_fd` are the train and test federated datasets, respectively.\n",
        "\n",
        "We can look at some of the metadata about the federated dataset, like the total number of clients, client ids, and number of examples for each client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 70,
          "status": "ok",
          "timestamp": 1622686192351,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "0RZVyPIA_Rrk",
        "outputId": "885c86dc-8e9f-4cc1-b78b-3e357bb524fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_clients = 715\n",
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 5\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 13\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 15\n"
          ]
        }
      ],
      "source": [
        "print('num_clients =', train_fd.num_clients())\n",
        "\n",
        "# train_fd.client_ids() is a generator of client ids.\n",
        "# itertools has efficient and convenient functions for working with generators.\n",
        "for client_id in itertools.islice(train_fd.client_ids(), 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', train_fd.client_size(client_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7urRdOQCFGoB"
      },
      "source": [
        "As seen in the output, there are 715 total clients in the Shakespeare dataset.\n",
        "Each client has a unique client ID that can be used to query metadata about that client such as the number of examples that client has.\n",
        "\n",
        "We can also query the dataset for a client using their client ID and `fedjax.FederatedData.get_client()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1622686262840,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "0z6pyKBoFGXV",
        "outputId": "d11f63da-da3b-4244-f372-d143870b72c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u003cfedjax.core.client_datasets.ClientDataset object at 0x7f357713fc88\u003e\n"
          ]
        }
      ],
      "source": [
        "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
        "client_dataset = train_fd.get_client(client_id)\n",
        "print(client_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf-sIWWfGVJf"
      },
      "source": [
        "The output of `fedjax.FederatedData.get_client()` is a `fedjax.ClientDataset` object that stores all the examples for a given client as well as built-in methods for batching, shuffling, and iterating over the data. Later, we will go more deeply into `fedjax.ClientDataset` and its structure and built-in methods, but for now, just consider `fedjax.ClientDataset` as all the examples for a given client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9836hb_oHwzt"
      },
      "source": [
        "### Client datasets structure\n",
        "\n",
        "`fedjax.ClientDataset` is the interface for client datasets. We make the assumption that individual client datasets are small and can easily fit in memory. This assumption is also reflected in many of our design decisions.\n",
        "\n",
        "**ClientDataset = examples + preprocessor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-RGKRTrSSY0"
      },
      "outputs": [],
      "source": [
        "# We cap max sentence length to 8.\n",
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data(sequence_length=8)\n",
        "cid = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "cds = train_fd.get_client(cid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx3L26llSuK2"
      },
      "source": [
        "The examples in a client dataset can be viewed as a table, where the rows are\n",
        "the individual examples, and the columns are the features (labels are viewed as\n",
        "a feature in this context).\n",
        "\n",
        "We use a column based representation when loading a dataset into memory.\n",
        "\n",
        "-   Each column is a NumPy array `x` of rank at least 1, where `x[i, ...]` is\n",
        "    the value of this feature for the `i`-th example.\n",
        "-   The complete set of examples is a dict-like object, from `str` feature\n",
        "    names, to the corresponding column values.\n",
        "\n",
        "Traditionally, a row based representation is used for representing the entire\n",
        "dataset, and a column based representation is used for a single batch.\n",
        "\n",
        "**In the context of federated learning, an individual client dataset is small\n",
        "enough to easily fit into memory so the same representation is used for the\n",
        "entire dataset and a batch.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 63,
          "status": "ok",
          "timestamp": 1622686193433,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "OPegAvJlStXB",
        "outputId": "e76f4b2c-99cf-4308-b9f1-337fd7a1f59e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12],\n",
              "        [75, 54, 74, 19, 16, 66, 47,  3],\n",
              "        [16, 67,  8, 67, 71, 47,  7, 61],\n",
              "        [16, 14,  4, 67, 47, 16, 48, 67],\n",
              "        [84, 67, 47,  7, 67, 48, 16, 12],\n",
              "        [78, 29, 75, 78, 33, 16, 66, 47],\n",
              "        [ 3, 16, 75, 73, 29, 11, 75, 76],\n",
              "        [32, 19, 65, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75],\n",
              "        [54, 74, 19, 16, 66, 47,  3, 16],\n",
              "        [67,  8, 67, 71, 47,  7, 61, 16],\n",
              "        [14,  4, 67, 47, 16, 48, 67, 84],\n",
              "        [67, 47,  7, 67, 48, 16, 12, 78],\n",
              "        [29, 75, 78, 33, 16, 66, 47,  3],\n",
              "        [16, 75, 73, 29, 11, 75, 76, 32],\n",
              "        [19, 65, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cds.all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usL6TCyiTFbl"
      },
      "source": [
        "For Shakespeare, we are training a character-level language model, where the task is next character prediction, so the features are:\n",
        "\n",
        "- `x` is a list of right-shifted sentences, e.g. `sentence[:-1]`\n",
        "- `y` is a list of left-shifted sentences, e.g. `sentence[1:]`\n",
        "\n",
        "This way, the pair `x[i][j]` and `y[i][j]` corresponds to the previous and next characters, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 69,
          "status": "ok",
          "timestamp": 1622686193603,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "TrEBFCwhVbF5",
        "outputId": "4ba357cf-cfd7-42a8-d23f-c82f18babe67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x [ 1 55 67 84 67 47  7 67]\n",
            "y [55 67 84 67 47  7 67 48]\n"
          ]
        }
      ],
      "source": [
        "examples = cds.all_examples()\n",
        "print('x', examples['x'][0])\n",
        "print('y', examples['y'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joe6K_cnVZuj"
      },
      "source": [
        "However, you probably noticed that `x` and `y` are arrays of integers not text. This is because some minimal preprocessing was done as part of `fedjax.datasets.shakespeare.load_data()` that did simple character look up that mapped characters to integer IDs. Later, we'll go over how this preprocessing was applied and how to add your own custom preprocessing.\n",
        "\n",
        "We can also view the unprocessed version of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1622686302561,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "qJ41cLCUS1GA",
        "outputId": "4e4e7f48-2f3a-4d76-dcc7-8803067868da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'snippets': array([b\"If we be not reliev'd within this hour,\",\n",
              "        b\"Let's hear him, for the things he speaks\",\n",
              "        b'May concern Caesar.\\nSwoons rather; for so bad a prayer as his',\n",
              "        b\"We must return to th' court of guard. The night\\nIs shiny, and they say we shall embattle\\nBy th' second hour i' th' morn.\\nEnobarbus?\",\n",
              "        b\"[Drums afar off ] Hark! the drums\\nDemurely wake the sleepers. Let us bear him\\nTo th' court of guard; he is of note. Our hour\\nIs fully out.\\n\"],\n",
              "       dtype=object)}"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')\n",
        "raw_cds = raw_fd.get_client(client_id)\n",
        "raw_cds.all_examples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4urvo2ffUsA"
      },
      "source": [
        "## Accessing federated datasets\n",
        "\n",
        "The previous methods work well for querying data for a *single* client for exploring the dataset. However, we often want to query for multiple client datasets at the same time. In most FL algorithms, tens to hundreds of clients particpate in each training round, and for large federated datasets, it is not feasible to load all client datasets into memory at once (whereas loading a single client dataset is assumed to be feasible).\n",
        "\n",
        "In light of this, we offer more efficient methods for querying multiple client datasets that we **STRONGLY** recommend you use that leverage the fact that sequential read is much faster than random read for most storage technologies.\n",
        "\n",
        "**We'll go through each acces method from the MOST efficient to the LEAST efficient.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6GZasNofwSS"
      },
      "outputs": [],
      "source": [
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fknJ_vA_L1er"
      },
      "source": [
        "### `clients()` and `shuffled_clients()`\n",
        "\n",
        "**Fastest** sequential read friendly access.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1622686192628,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "48iWUX-0Il52",
        "outputId": "7307ce2f-f290-40ee-924e-8bb65e243ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clients = \u003cgenerator object SQLiteFederatedData.clients at 0x7f357710e258\u003e\n",
            "shuffled_clients = \u003cgenerator object SQLiteFederatedData.shuffled_clients at 0x7f357710e150\u003e\n"
          ]
        }
      ],
      "source": [
        "# clients() and shuffled_clients() are sequential read friendly.\n",
        "clients = train_fd.clients()\n",
        "shuffled_clients = train_fd.shuffled_clients(buffer_size=100, seed=0)\n",
        "print('clients =', clients)\n",
        "print('shuffled_clients =', shuffled_clients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7-bQUKPLunl"
      },
      "source": [
        "They are generators, so in order to use them, we need to iterator over them.\n",
        "\n",
        "`clients()` returns clients in a deterministic order, where each \"client\" is a tuple of (client_id, client_dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1622686192710,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "9IFLDlocLwTV",
        "outputId": "f689c986-6e4d-435d-81cd-6e0ef8a88244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 6\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 24\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 8\n"
          ]
        }
      ],
      "source": [
        "for client_id, client_dataset in itertools.islice(clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTGrSHMUMLzJ"
      },
      "source": [
        "`shuffled_clients()` is like `clients()` but allows repeated buffered shuffling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 59,
          "status": "ok",
          "timestamp": 1622686192860,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "JTFJO7k1MOr4",
        "outputId": "700bcacf-0210-46ab-9394-c6f41665b250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shuffled_clients()\n",
            "client_id = b'0a18c2501d441fef:THE_TRAGEDY_OF_KING_LEAR_FLUTE'\n",
            "# examples = 12\n",
            "client_id = b'136c5586b7271525:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_GLOUCESTER'\n",
            "# examples = 381\n",
            "client_id = b'0d642a9b4bb27187:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_MESSENGER'\n",
            "# examples = 78\n"
          ]
        }
      ],
      "source": [
        "print('shuffled_clients()')\n",
        "for client_id, client_dataset in itertools.islice(shuffled_clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGd1NDhJMW8R"
      },
      "source": [
        "### `get_clients()`\n",
        "\n",
        "**Slower** than `clients()` since it requires random read but uses prefetching to ameliorate the cost of random read access. This will return a generator of tuples of (client_id, client_dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1622686192987,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "WGTz8aotMn9Q",
        "outputId": "11402e77-4af8-4a64-8529-cd2b77361e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 49\n",
            "client_id = b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN'\n",
            "# examples = 1\n",
            "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
            "# examples = 2\n"
          ]
        }
      ],
      "source": [
        "client_ids = [\n",
        "    b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN',\n",
        "    b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN',\n",
        "    b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "]\n",
        "for client_id, client_dataset in train_fd.get_clients(client_ids):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6EV1zTMoWE"
      },
      "source": [
        "### `get_client()`\n",
        "\n",
        "**Slowest** way of accessing client datasets. We usually reserve this method only for interactive exploration of a small number of clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 65,
          "status": "ok",
          "timestamp": 1622686193155,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "MNaCOkFnM6JU",
        "outputId": "b45edb02-50e2-4dd3-c142-d4de0ff6fdd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 49\n"
          ]
        }
      ],
      "source": [
        "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
        "print('client_id =', client_id)\n",
        "print('# examples =', len(train_fd.get_client(client_id)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r5jfm0V2YH"
      },
      "source": [
        "## Batching client datasets\n",
        "\n",
        "Next we'll go over different methods of batching and iterating over the client dataset. All the following methods can be invoked in 2 ways:\n",
        "\n",
        "1. Using a hyperparams object. This is the recommended way in library code. `batch_fn(hparams)`.\n",
        "2. Using keyword arguments. The keyword arguments are used to construct a new hyperparams object, or override an existing one. `batch_fn(batch_size=2)` or `batch_fn(hparams, batch_size=2)` to override `batch_size`.\n",
        "\n",
        "For the most part, we'll use method 2 for this colab, but we highly recommend using method 1 for writing library code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcGaaGkXf5lz"
      },
      "outputs": [],
      "source": [
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data(sequence_length=8)\n",
        "cid = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "cds = train_fd.get_client(cid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2qFa8HVyar"
      },
      "source": [
        "### `padded_batch()`\n",
        "\n",
        "Produces preprocessed padded batches in a fixed sequential order **for evaluation**.\n",
        "\n",
        "When the number of examples in the dataset is not a multiple of `batch_size`,\n",
        "the final batch may be smaller than `batch_size`. This may lead to [a large\n",
        "number of JIT recompilations](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html). This can be circumvented by padding the final\n",
        "batch to a small number of fixed sizes controlled by `num_batch_size_buckets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1622686193955,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "cRPnF2YOXU6e",
        "outputId": "5eacaa17-2d44-4f4f-e847-480c0e5d4b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches = 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75]], dtype=int32),\n",
              " '__mask__': array([ True,  True,  True,  True,  True,  True,  True,  True])}"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use list() to consume generator and store in memory.\n",
        "padded_batches = list(cds.padded_batch(batch_size=8, num_batch_size_buckets=3))\n",
        "print('# batches =', len(padded_batches))\n",
        "padded_batches[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WzTr7zBXVPj"
      },
      "source": [
        "All batches contain an extra bool feature keyed by `__mask__`.\n",
        "`batch[__mask__][i]` tells us whether the `i`-th example in this batch\n",
        "is an actual example (`batch[__mask__][i] == True`), or a padding\n",
        "example (`batch[__mask__][i] == False`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zMXxpp8ZN5F"
      },
      "source": [
        "We repeatedly halve the batch size up to `num_batch_size_buckets - 1` times, until\n",
        "we find the smallest one that is also \u003e= the size of the final batch. Therefore\n",
        "if `batch_size \u003c 2^num_batch_size_buckets`, fewer bucket sizes will be actually\n",
        "used. This will be seen when we look at the final batch that only has 4 examples when the original batch size was 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 85,
          "status": "ok",
          "timestamp": 1622686194118,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "NwqYDivRZR4T",
        "outputId": "ad2d4eb4-9074-4439-a106-db89e55f20a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'__mask__': array([ True,  True,  True, False]),\n",
              " 'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_batches[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49yb3Bh3Ue4m"
      },
      "source": [
        "### `shuffle_repeat_batch()`\n",
        "\n",
        "Produces preprocessed batches in a shuffled and repeated order **for training**.\n",
        "\n",
        "Shuffling is done without replacement, therefore for a dataset of N examples,\n",
        "the first `ceil(N/batch_size)` batches are guarranteed to cover the entire\n",
        "dataset. Unlike `batch()` or `padded_batch()`, batches from\n",
        "`shuffle_repeat_batch()` always contain exactly `batch_size` examples. Also\n",
        "unlike TensorFlow, that holds even when `drop_remainder=False`.\n",
        "\n",
        "By default the iteration stops after the first epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 77,
          "status": "ok",
          "timestamp": 1622686194303,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "KlXliT7vawQa",
        "outputId": "e6ab79f2-f338-4710-95e9-083cf954b23c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('# batches')\n",
        "len(list(cds.shuffle_repeat_batch(batch_size=8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHMy2bUzaPH9"
      },
      "source": [
        "The number of batches produced from the iteration can be controlled by the `(num_epochs, num_steps,\n",
        "drop_remainder)` combination:\n",
        "\n",
        "If both `num_epochs` and `num_steps` are None, the shuffle-repeat process continues forever.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 74,
          "status": "ok",
          "timestamp": 1622686194443,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "2PLFH_zCbfmr",
        "outputId": "3a970932-5635-46e8-dc0b-1ce7cd3df605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "infinite_bs = cds.shuffle_repeat_batch(\n",
        "    batch_size=8, num_epochs=None, num_steps=None)\n",
        "for i, b in zip(range(6), infinite_bs):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtdePTEobgEL"
      },
      "source": [
        "If `num_epochs` is set and `num_steps` is None, as few batches as needed to go\n",
        "over the dataset this many passes are produced. Further,\n",
        "\n",
        "-   If `drop_remainder` is False (the default), the final batch is filled with\n",
        "    additionally sampled examples to contain `batch_size` examples.\n",
        "-   If `drop_remainder` is True, the final batch is dropped if it contains fewer\n",
        "    than `batch_size` examples. This may result in examples being skipped when\n",
        "    `num_epochs=1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 65,
          "status": "ok",
          "timestamp": 1622686194586,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "xTUDo9E2blJk",
        "outputId": "3b926d22-dc6f-4625-ccd3-33c309844803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ drop_remainder=False\n",
            "3\n",
            "# batches w/ drop_remainder=True\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ drop_remainder=False')\n",
        "print(len(list(cds.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None))))\n",
        "print('# batches w/ drop_remainder=True')\n",
        "print(len(list(cds.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None, drop_remainder=True))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxYReBTkblZN"
      },
      "source": [
        "If `num_steps` is set and `num_steps` is None, exactly this many batches are\n",
        "produced. `drop_remainder` has no effect in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 17,
          "status": "ok",
          "timestamp": 1622686194705,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "QNPvIWdTbnp4",
        "outputId": "cfeecfc5-051f-4d4c-d64e-a6a33cfa994d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ num_steps set and drop_remainder=True\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ num_steps set and drop_remainder=True')\n",
        "print(len(list(cds.shuffle_repeat_batch(batch_size=8, num_epochs=None, num_steps=3, drop_remainder=True))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qARHz3mPbn26"
      },
      "source": [
        "If both `num_epochs` and `num_steps` are set, the fewer number of batches\n",
        "between the two conditions are produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1622686194817,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "dMt9WOaQbpry",
        "outputId": "569073a1-9e33-41af-e4cb-f5542680b6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# batches w/ num_epochs and num_steps set\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print('# batches w/ num_epochs and num_steps set')\n",
        "print(len(list(cds.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=6))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptjP1zwalp7"
      },
      "source": [
        "If reproducible iteration order is desired, a fixed `seed` can be used. When\n",
        "`seed` is None, repeated iteration over the same object may produce batches in a\n",
        "different order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 60,
          "status": "ok",
          "timestamp": 1622686194964,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "lIZjo5F4bsLO",
        "outputId": "1f0c7588-8b85-40a3-98ce-5344991b0ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 27, 67, 23, 26, 47,  3, 27]], dtype=int32), 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
            "       [27, 67, 23, 26, 47,  3, 27, 16]], dtype=int32)}\n",
            "{'x': array([[16, 14,  4, 67, 47, 16, 48, 67],\n",
            "       [48, 16, 13, 32, 33, 14, 11, 78]], dtype=int32), 'y': array([[14,  4, 67, 47, 16, 48, 67, 84],\n",
            "       [16, 13, 32, 33, 14, 11, 78, 76]], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "# Random shuffling.\n",
        "print(list(cds.shuffle_repeat_batch(batch_size=2, seed=None))[0])\n",
        "# Fixed shuffling.\n",
        "print(list(cds.shuffle_repeat_batch(batch_size=2, seed=0))[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UVh3L_zV030"
      },
      "source": [
        "### `batch()`\n",
        "\n",
        "Produces preprocessed batches in a fixed sequential order.\n",
        "\n",
        "The final batch may contain fewer than `batch_size` examples. If used directly,\n",
        "that may result in a large number of JIT recompilations. **Therefore we\n",
        "recommended using `padded_batch()` or `shuffle_repeat_batch()` instead in most scenarios.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 54,
          "status": "ok",
          "timestamp": 1622686195110,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "ZFO3jftTe8ua",
        "outputId": "66f355ba-7826-4452-9c65-08e0d751972b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batches = list(cds.batch(batch_size=8))\n",
        "batches[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybw5LyduIuDC"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Preprocessing can be done at two levels\n",
        "\n",
        "- The batch level with `fedjax.BatchPreprocessor`\n",
        "- The client dataset level with `fedjax.ClientPreprocessor`\n",
        "\n",
        "**Examples of preprocessing possible at either the client dataset level, or\n",
        "the batch level**\n",
        "\n",
        "Such preprocessing is deterministic, and strictly per-example.\n",
        "\n",
        "- Casting a feature from `int8` to `float32`.\n",
        "- Adding a new feature derived from existing features.\n",
        "- Remove a feature (although the better place to do so is at the dataset\n",
        "  level).\n",
        "\n",
        "A simple rule for deciding where to carry out the preprocessing in this case\n",
        "is the following,\n",
        "\n",
        "- Does this make batching cheaper (e.g. removing features)? If so, do it at\n",
        "  the dataset level.\n",
        "- Otherwise, do it at the batch level.\n",
        "\n",
        "Assuming preprocessing time is linear in the number of examples, preprocessing\n",
        "at the batch level has the benefit of evenly distributing host compute work,\n",
        "which may overlap better with asynchronous JAX compute work on GPU/TPU.\n",
        "\n",
        "**Examples of preprocessing only possible at the batch level**\n",
        "\n",
        "- Data augmentation (e.g. random cropping).\n",
        "- Padding at the batch size dimension.\n",
        "\n",
        "**Examples of preprocessing only possible at the dataset level**\n",
        "\n",
        "- Those that require knowing the client id.\n",
        "- Capping the number of examples.\n",
        "- Altering what it means to be an example: e.g. in certain language model\n",
        "  setups, sentences are concatenated and then split into equal sized chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 62,
          "status": "ok",
          "timestamp": 1622686195250,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "owvH0JlqgQef",
        "outputId": "7b5c8bbf-60de-4a54-a1f7-7f0910ad7bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ]
        }
      ],
      "source": [
        "# Load unpreprocessed data.\n",
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEmJP73jZZS"
      },
      "source": [
        "### Applying preprocessing\n",
        "\n",
        "Actually applying the preprocessing is usally done on the `fedjax.FederatedData`\n",
        "using `preprocess_client()` and `preprocess_batch()` for the client dataset\n",
        "level and batch level, respectively.\n",
        "\n",
        "Below, we will walk through an example preprocessing pipeline for Shakespeare\n",
        "that turns text into sequences of integer labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CGaM5v6mfDJ"
      },
      "outputs": [],
      "source": [
        "def _build_look_up_table(vocab, num_reserved):\n",
        "  \"\"\"Builds a look-up table from a byte to its integer label.\"\"\"\n",
        "  oov = num_reserved + len(vocab)\n",
        "  vocab_size = oov + 1\n",
        "  table = np.full([256], oov, dtype=np.int32)\n",
        "  for i, c in enumerate(vocab):\n",
        "    table[c] = num_reserved + i\n",
        "  return table, vocab_size\n",
        "\n",
        "\n",
        "# Vocabulary re-used from the Federated Learning for Text Generation tutorial.\n",
        "# https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\n",
        "TABLE, VOCAB_SIZE = _build_look_up_table(\n",
        "    b'dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"\u0026*.26:\\naeimquyAEIMQUY]!%)-159\\r',\n",
        "    num_reserved=3)\n",
        "OOV = VOCAB_SIZE - 1\n",
        "# Reserved labels.\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ByT_b9zmFBP"
      },
      "source": [
        "All snippets in a client dataset are first joined into a single sequence (with\n",
        "BOS/EOS added), and then split into pairs of `sequence_length` chunks for\n",
        "language model training. For example, with sequence_length=3, `[b'ABCD', b'E']`\n",
        "becomes\n",
        "\n",
        "```\n",
        "Input sequences:  [[BOS, A, B], [C, D, EOS],   [BOS, E, PAD]]\n",
        "Output seqeunces: [[A, B, C],   [D, EOS, BOS], [E, EOS, PAD]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PISTQyClPdo"
      },
      "outputs": [],
      "source": [
        "def preprocess_client(client_id, examples, sequence_length):\n",
        "  \"\"\"Turns snippets into sequences of integer labels.\"\"\"\n",
        "  del client_id\n",
        "  snippets = examples['snippets']\n",
        "  # Join all snippets into a single label sequence.\n",
        "  joined_length = sum(len(i) + 2 for i in snippets)\n",
        "  joined = np.zeros([joined_length], dtype=np.int32)\n",
        "  offset = 0\n",
        "  for i in snippets:\n",
        "    joined[offset] = BOS\n",
        "    joined[offset + 1:offset + 1 + len(i)] = TABLE[list(i)]\n",
        "    joined[offset + 1 + len(i)] = EOS\n",
        "    offset += len(i) + 2\n",
        "  # Split into input/output sequences of size `sequence_length`.\n",
        "  padded_length = ((joined_length - 1 + sequence_length - 1) //\n",
        "                   sequence_length * sequence_length)\n",
        "  input_labels = np.full([padded_length], PAD, dtype=np.int32)\n",
        "  input_labels[:joined_length - 1] = joined[:-1]\n",
        "  output_labels = np.full([padded_length], PAD, dtype=np.int32)\n",
        "  output_labels[:joined_length - 1] = joined[1:]\n",
        "  return {\n",
        "      'x': input_labels.reshape([-1, sequence_length]),\n",
        "      'y': output_labels.reshape([-1, sequence_length])\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEtuvYvVltSp"
      },
      "source": [
        "The output features will be (M below is possibly different from N in\n",
        "load_split):\n",
        "\n",
        "-   `x`: [M, sequence_length] int32 input labels, in the range of [0,\n",
        "    shakespeare.VOCAB_SIZE)\n",
        "-   `y`: [M, sequence_length] int32 output labels, in the range of [0,\n",
        "    shakespeare.VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 73,
          "status": "ok",
          "timestamp": 1622686195828,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "moZ5YA7sl7Tg",
        "outputId": "3346ee53-70e4-45e0-807a-b24ba310798e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw unprocessed client dataset\n",
            "{'snippets': array([b'Re-enter POSTHUMUS, and seconds the Britons; they rescue\\nCYMBELINE, and exeunt. Then re-enter LUCIUS and IACHIMO,\\n                     with IMOGEN\\n'],\n",
            "      dtype=object)}\n",
            "Preprocessed client dataset\n",
            "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67, 48, 16],\n",
            "       [13, 32, 33, 14, 11, 78, 76, 78, 33, 19],\n",
            "       [16, 66, 47,  3, 16, 27, 67, 23, 26, 47],\n",
            "       [ 3, 27, 16,  7,  4, 67, 16, 51, 48, 68],\n",
            "       [ 7, 26, 47, 27, 42, 16,  7,  4, 67, 72],\n",
            "       [16, 48, 67, 27, 23, 71, 67, 65, 29, 79],\n",
            "       [76, 51, 74, 12, 75, 54, 74, 19, 16, 66],\n",
            "       [47,  3, 16, 67,  8, 67, 71, 47,  7, 61],\n",
            "       [16, 14,  4, 67, 47, 16, 48, 67, 84, 67],\n",
            "       [47,  7, 67, 48, 16, 12, 78, 29, 75, 78],\n",
            "       [33, 16, 66, 47,  3, 16, 75, 73, 29, 11],\n",
            "       [75, 76, 32, 19, 65, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 28, 68,  7,  4],\n",
            "       [16, 75, 76, 32, 30, 74, 54, 65,  0,  0]], dtype=int32), 'y': array([[55, 67, 84, 67, 47,  7, 67, 48, 16, 13],\n",
            "       [32, 33, 14, 11, 78, 76, 78, 33, 19, 16],\n",
            "       [66, 47,  3, 16, 27, 67, 23, 26, 47,  3],\n",
            "       [27, 16,  7,  4, 67, 16, 51, 48, 68,  7],\n",
            "       [26, 47, 27, 42, 16,  7,  4, 67, 72, 16],\n",
            "       [48, 67, 27, 23, 71, 67, 65, 29, 79, 76],\n",
            "       [51, 74, 12, 75, 54, 74, 19, 16, 66, 47],\n",
            "       [ 3, 16, 67,  8, 67, 71, 47,  7, 61, 16],\n",
            "       [14,  4, 67, 47, 16, 48, 67, 84, 67, 47],\n",
            "       [ 7, 67, 48, 16, 12, 78, 29, 75, 78, 33],\n",
            "       [16, 66, 47,  3, 16, 75, 73, 29, 11, 75],\n",
            "       [76, 32, 19, 65, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 28, 68,  7,  4, 16],\n",
            "       [75, 76, 32, 30, 74, 54, 65,  2,  0,  0]], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "cid = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "raw_cds = raw_fd.get_client(cid)\n",
        "print('Raw unprocessed client dataset')\n",
        "print(raw_cds.all_examples())\n",
        "\n",
        "preprocess = functools.partial(preprocess_client, sequence_length=10)\n",
        "cds = raw_fd.preprocess_client(preprocess).get_client(cid)\n",
        "print('Preprocessed client dataset')\n",
        "print(cds.all_examples())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNY2M7hJgCCV"
      },
      "source": [
        "### `BatchPreprocessor`\n",
        "\n",
        "Preprocessing on a batch of examples can be easily done via a chain of\n",
        "functions. A `Preprocessor` object holds the chain of functions, and applies\n",
        "the transformation on a batch of examples.\n",
        "\n",
        "`fedjax.BatchPreprocessor` holds a chain of preprocessing functions, and applies\n",
        "them in order on batched examples. Each individual preprocessing function\n",
        "operates over multiple examples, instead of just 1 example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 64,
          "status": "ok",
          "timestamp": 1622686196016,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "z0-AE-N-hZ8s",
        "outputId": "81b55314-7081-4c5a-e4ce-a483403c0033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pixels': array([[0.45102459, 0.76206138, 0.06551379, ..., 0.45446418, 0.89527442,\n",
              "         0.56221184],\n",
              "        [0.67933712, 0.16994017, 0.57733109, ..., 0.7888319 , 0.70922089,\n",
              "         0.80357344]]), 'label': array([6, 8]), 'binary_label': array([0, 0])}"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = fedjax.BatchPreprocessor([\n",
        "  # Flattens `pixels`.\n",
        "  lambda x: {**x, 'pixels': x['pixels'].reshape([-1, 28 * 28])},\n",
        "  # Introduce `binary_label`.\n",
        "  lambda x: {**x, 'binary_label': x['label'] % 2},\n",
        "])\n",
        "fake_emnist = {\n",
        "  'pixels': np.random.uniform(size=(2, 28, 28)),\n",
        "  'label': np.random.randint(10, size=(2,))\n",
        "}\n",
        "preprocessor(fake_emnist)\n",
        "# Produces a dict of [2, 28*28] \"pixels\", [2,] \"label\" and \"binary_label\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A2xxW-IhXUe"
      },
      "source": [
        "Given a `fedjax.BatchPreprocessor`, a new `fedjax.BatchPreprocessor` can be\n",
        "created with an additional preprocessing function appended to the chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 56,
          "status": "ok",
          "timestamp": 1622686196146,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "-GGDMr3jhudG",
        "outputId": "29378532-53a7-4b67-eeef-82dc2ecf3bc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pixels': array([[0.45102459, 0.76206138, 0.06551379, ..., 0.45446418, 0.89527442,\n",
              "         0.56221184],\n",
              "        [0.67933712, 0.16994017, 0.57733109, ..., 0.7888319 , 0.70922089,\n",
              "         0.80357344]]),\n",
              " 'label': array([6, 8]),\n",
              " 'binary_label': array([0, 0]),\n",
              " 'sum_pixels': array([390.24969764, 384.08759272])}"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Continuing from the previous example.\n",
        "new_preprocessor = preprocessor.append(\n",
        "  lambda x: {**x, 'sum_pixels': np.sum(x['pixels'], axis=1)})\n",
        "new_preprocessor(fake_emnist)\n",
        "# Produces a dict of [2, 28*28] \"pixels\", [2,] \"sum_pixels\", \"label\" and\n",
        "# \"binary_label\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ERy_YGVhxNR"
      },
      "source": [
        "The main difference of this preprocessor and `fedjax.ClientPreprocessor` is that\n",
        "`fedjax.ClientPreprocessor` also takes `client_id` as input. Because of the\n",
        "identical representation between batched examples and all examples in a client\n",
        "dataset, certain preprocessing can be done with either\n",
        "`fedjax.BatchPreprocessor` or `fedjax.ClientPreprocessor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UcjabJgB0e"
      },
      "source": [
        "### `ClientPreprocessor`\n",
        "\n",
        "A chain of preprocessing functions on all examples of a client dataset.\n",
        "\n",
        "This is very similar to `fedjax.BatchPreprocessor`, with the main difference\n",
        "being that `ClientPreprocessor` also takes `client_id` as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 61,
          "status": "ok",
          "timestamp": 1622686196298,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "IdHnE6p8AHoe",
        "outputId": "916231ea-b078-44ca-cf7a-ef1785012fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'label': array([0, 2]), 'client_id_length': array([6, 6])}"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessor = fedjax.ClientPreprocessor([\n",
        "  # Adds `client_id_length`.\n",
        "  lambda cid, x: {**x, 'client_id_length': np.ones_like(x['label']) * len(cid)}\n",
        "])\n",
        "fake_emnist = {\n",
        "  'label': np.random.randint(10, size=(2,))\n",
        "}\n",
        "client_id = b'123456'\n",
        "preprocessor(client_id, fake_emnist)\n",
        "# Produces a dict of [2,] \"label\" and \"client_id_length\"."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "dataset_tutorial.ipynb",
      "provenance": [
        {
          "file_id": "1E0Bjy92M9C-CbZVzQzJC1n31F7SrWwPY",
          "timestamp": 1622044731855
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
