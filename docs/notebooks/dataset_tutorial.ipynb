{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVlzn5lPxReI"
      },
      "source": [
        "# Federated datasets\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/fedjax/blob/main/docs/notebooks/dataset_tutorial.ipynb)\n",
        "\n",
        "This tutorial introduces datasets in FedJAX and how to work with them. By completing this tutorial, we'll learn about the best practices for working with datasets.\n",
        "\n",
        "**NOTE: For datasets, we operate over NumPy arrays NOT JAX arrays.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYNAdtNu7Nlf"
      },
      "source": [
        "# Uncomment these to install fedjax.\n",
        "# !pip install fedjax\n",
        "# !pip install --upgrade git+https://github.com/google/fedjax.git\n",
        "# !pip install tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XANytMDXZbAH"
      },
      "source": [
        "import functools\n",
        "import itertools\n",
        "import fedjax\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnfi9sx6zC6E"
      },
      "source": [
        "## What are datasets in federated learning?\n",
        "\n",
        "In the context of federated learning (FL), data is decentralized across clients, with each client having their own local set of examples. In light of this, we refer to two levels of organization for datasets:\n",
        "\n",
        "- Federated dataset: A collection of clients, each with their own local datasets and metadata\n",
        "- Client dataset: The set of local examples for a particular client\n",
        "\n",
        "We can think of federated data as a mapping from client ids to client datasets and client datasets as a list of examples.\n",
        "\n",
        "```\n",
        "federated_data = {\n",
        "  'client0': ['a', 'b', 'c'],\n",
        "  'client1': ['d', 'e'],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qttyzji6-LU"
      },
      "source": [
        "### Federated datasets\n",
        "\n",
        "`fedjax.FederatedData` is the interface for accessing all federated datasets.\n",
        "\n",
        "FedJAX comes packaged with multiple federated datasets, and we will look at the Shakespeare dataset as an example. The Shakespeare dataset is created from [The Complete Works of Shakespeare](https://www.gutenberg.org/files/100/100-0.txt), by treating each character in the play as a \"client\", and their dialogue lines as the examples.\n",
        "\n",
        "FedJAX organizes federated datasets as Python modules. `load_data()` from a A dataset module loads all predefined splits together. In the case of the Shakespeare dataset, `load_data()` returns two splits: train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxeEfaKb3J9N"
      },
      "source": [
        "# We cap max sentence length to 8.\n",
        "train_fd, test_fd = fedjax.datasets.shakespeare.load_data(sequence_length=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vt7LCVV_TZl"
      },
      "source": [
        "`fedjax.FederatedData` provides methods for accessing metadata about the federated dataset, like the total number of clients, client ids, and number of examples for each client.\n",
        "\n",
        "As seen in the output, there are 715 total clients in the Shakespeare dataset.\n",
        "Each client has a unique client ID that can be used to query metadata about that client such as the number of examples that client has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RZVyPIA_Rrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de880fa1-9ed6-400d-c709-7e36bfec17ec"
      },
      "source": [
        "print('num_clients =', train_fd.num_clients())\n",
        "\n",
        "# train_fd.client_ids() is a generator of client ids.\n",
        "# itertools has efficient and convenient functions for working with generators.\n",
        "for client_id in itertools.islice(train_fd.client_ids(), 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', train_fd.client_size(client_id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_clients = 715\n",
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 5\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 13\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8FlpRf4B2LQ"
      },
      "source": [
        "As we notice, the client ids start with a random set of bits. This is to ensure that one can serially process clients and still get a random deterministic order, which is helpful in reading large datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7urRdOQCFGoB"
      },
      "source": [
        "### Client datasets\n",
        "\n",
        "We can query the dataset for a client from a federated dataset using their client ID and `fedjax.FederatedData.get_client()`. The output of `fedjax.FederatedData.get_client()` is a `fedjax.ClientDataset`. A `fedjax.ClientDataset` object\n",
        "\n",
        "-   Stores all the examples for a given client and any preprocessing that should be applied.\n",
        "-   Provides methods for batching, shuffling, and iterating over preprocessed examples.\n",
        "\n",
        "In other words, **ClientDataset = examples + preprocessor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z6pyKBoFGXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8386b69-c8f4-4148-d37e-6f726a5b3473"
      },
      "source": [
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "client_dataset = train_fd.get_client(client_id)\n",
        "print(client_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<fedjax.core.client_datasets.ClientDataset object at 0x7f340f682750>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx3L26llSuK2"
      },
      "source": [
        "FedJAX makes the assumption that individual client datasets are small and can easily fit in memory. This assumption is also reflected in many of FedJAX's design decisions. The examples in a client dataset can be viewed as a table, where the rows are\n",
        "the individual examples, and the columns are the features (labels are viewed as\n",
        "a feature in this context).\n",
        "\n",
        "FedJAX uses a column based representation when loading a dataset into memory.\n",
        "\n",
        "-   Each column is a NumPy array `x` of rank at least 1, where `x[i, ...]` is\n",
        "    the value of this feature for the `i`-th example.\n",
        "-   The complete set of examples is a dict-like object, from `str` feature\n",
        "    names, to the corresponding column values.\n",
        "\n",
        "Traditionally, a row based representation is used for representing the entire\n",
        "dataset, and a column based representation is used for a single batch.\n",
        "\n",
        "**In the context of federated learning, an individual client dataset is small\n",
        "enough to easily fit into memory so the same representation is used for the\n",
        "entire dataset and a batch.**\n",
        "\n",
        "The examples of a single client can be viewed by calling `all_examples()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPegAvJlStXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f515d1f6-d37a-4a5f-b663-857882114738"
      },
      "source": [
        "client_dataset.all_examples()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12],\n",
              "        [75, 54, 74, 19, 16, 66, 47,  3],\n",
              "        [16, 67,  8, 67, 71, 47,  7, 61],\n",
              "        [16, 14,  4, 67, 47, 16, 48, 67],\n",
              "        [84, 67, 47,  7, 67, 48, 16, 12],\n",
              "        [78, 29, 75, 78, 33, 16, 66, 47],\n",
              "        [ 3, 16, 75, 73, 29, 11, 75, 76],\n",
              "        [32, 19, 65, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75],\n",
              "        [54, 74, 19, 16, 66, 47,  3, 16],\n",
              "        [67,  8, 67, 71, 47,  7, 61, 16],\n",
              "        [14,  4, 67, 47, 16, 48, 67, 84],\n",
              "        [67, 47,  7, 67, 48, 16, 12, 78],\n",
              "        [29, 75, 78, 33, 16, 66, 47,  3],\n",
              "        [16, 75, 73, 29, 11, 75, 76, 32],\n",
              "        [19, 65, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usL6TCyiTFbl"
      },
      "source": [
        "For Shakespeare, we are training a character-level language model, where the task is next character prediction, so the features are:\n",
        "\n",
        "- `x` is a list of right-shifted sentences, e.g. `sentence[:-1]`\n",
        "- `y` is a list of left-shifted sentences, e.g. `sentence[1:]`\n",
        "\n",
        "This way, `y[i][j]` corresponds to the next character after `x[i][j]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrEBFCwhVbF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b21cc0c-fc83-4b46-84aa-3487580c768c"
      },
      "source": [
        "examples = client_dataset.all_examples()\n",
        "print('x', examples['x'][0])\n",
        "print('y', examples['y'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x [ 1 55 67 84 67 47  7 67]\n",
            "y [55 67 84 67 47  7 67 48]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joe6K_cnVZuj"
      },
      "source": [
        "However, you probably noticed that `x` and `y` are arrays of integers not text. This is because  `fedjax.datasets.shakespeare.load_data()` does some minimal preprocessing, such as a simple character look up that mapped characters to integer IDs. Later, we'll go over how this preprocessing was applied and how to add your own custom preprocessing.\n",
        "\n",
        "For comparison, here's the unprocessed version of the same client dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ41cLCUS1GA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69218c25-7e25-4586-c463-f3659cf259ca"
      },
      "source": [
        "# Unlike load_data(), load_split() always loads a single unprocessed split.\n",
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')\n",
        "raw_fd.get_client(client_id).all_examples()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'snippets': array([b'Re-enter POSTHUMUS, and seconds the Britons; they rescue\\nCYMBELINE, and exeunt. Then re-enter LUCIUS and IACHIMO,\\n                     with IMOGEN\\n'],\n",
              "       dtype=object)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4urvo2ffUsA"
      },
      "source": [
        "## Accessing client datasets from `fedjax.FederatedData`\n",
        "\n",
        "`fedjax.FederatedData.get_client()` works well for querying data for a *single* client for exploring the dataset. However, we often want to query for multiple client datasets at the same time. In most FL algorithms, tens to hundreds of clients particpate in each training round. If we are not careful, our code can spend a lot of time loading data, leaving the accelerators (GPU or TPU) to idle.\n",
        "\n",
        "In light of this, `fedjax.FederatedData` offers more efficient methods for querying multiple client datasets.\n",
        "\n",
        "**We'll go through each access method from the MOST efficient to the LEAST efficient.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fknJ_vA_L1er"
      },
      "source": [
        "### `clients()` and `shuffled_clients()`\n",
        "\n",
        "**Fastest** sequential read friendly access. As we stated earlier, the client ids are appended with random bits. Hene, even sequential reads will go over clients in a pseudo-random order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48iWUX-0Il52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53d2e51-c26e-4c31-9e8e-7d3148627891"
      },
      "source": [
        "# clients() and shuffled_clients() are sequential read friendly.\n",
        "clients = train_fd.clients()\n",
        "shuffled_clients = train_fd.shuffled_clients(buffer_size=100, seed=0)\n",
        "print('clients =', clients)\n",
        "print('shuffled_clients =', shuffled_clients)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clients = <generator object SQLiteFederatedData.clients at 0x7f346e2da850>\n",
            "shuffled_clients = <generator object SQLiteFederatedData.shuffled_clients at 0x7f340f689b50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7-bQUKPLunl"
      },
      "source": [
        "They are generators, so we iterate over them to get the individual client datasets as tuples of (client_id, client_dataset).\n",
        "\n",
        "`clients()` returns clients in an unspecified deterministic order. It is useful for going over the entire federated dataset for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IFLDlocLwTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c02b785-1d53-4bfc-d4ae-b426641a1abf"
      },
      "source": [
        "# We use itertools.islice to select first three clients.\n",
        "for client_id, client_dataset in itertools.islice(clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client_id = b'00192e4d5c9c3a5b:ALL_S_WELL_THAT_ENDS_WELL_CENTURION'\n",
            "# examples = 53\n",
            "client_id = b'004309f15562402e:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_CAMPEIUS'\n",
            "# examples = 234\n",
            "client_id = b'00b20765b748920d:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_ALL'\n",
            "# examples = 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTGrSHMUMLzJ"
      },
      "source": [
        "`shuffled_clients()` provides a stream of infinitely repeating shuffled client datasets, using buffered shuffling. It is suitable for training rounds where a nearly random shuffling is good enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTFJO7k1MOr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73e9a1d-ad11-4cba-b3b3-6fd558e67d28"
      },
      "source": [
        "print('shuffled_clients()')\n",
        "for client_id, client_dataset in itertools.islice(shuffled_clients, 3):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffled_clients()\n",
            "client_id = b'0a18c2501d441fef:THE_TRAGEDY_OF_KING_LEAR_FLUTE'\n",
            "# examples = 115\n",
            "client_id = b'136c5586b7271525:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_GLOUCESTER'\n",
            "# examples = 3804\n",
            "client_id = b'0d642a9b4bb27187:THE_FIRST_PART_OF_KING_HENRY_THE_FOURTH_MESSENGER'\n",
            "# examples = 775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGd1NDhJMW8R"
      },
      "source": [
        "### `get_clients()`\n",
        "\n",
        "**Slower** than `clients()` since it requires random read but uses prefetching to hide the latency of random read access. This also returns a generator of tuples of (client_id, client_dataset), in the order of the input client_ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGTz8aotMn9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1530303b-f9f6-4f7f-982a-2781c566ffba"
      },
      "source": [
        "client_ids = [\n",
        "    b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN',\n",
        "    b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN',\n",
        "    b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "]\n",
        "for client_id, client_dataset in train_fd.get_clients(client_ids):\n",
        "  print('client_id =', client_id)\n",
        "  print('# examples =', len(client_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 483\n",
            "client_id = b'140784b36d08efbc:PERICLES__PRINCE_OF_TYRE_GHOST_OF_VAUGHAN'\n",
            "# examples = 5\n",
            "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
            "# examples = 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK6EV1zTMoWE"
      },
      "source": [
        "### `get_client()`\n",
        "\n",
        "**Slowest** way of accessing client datasets. We usually reserve this method only for interactive exploration of a small number of clients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNaCOkFnM6JU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f620d1d3-a04a-4039-ec72-724f51deda42"
      },
      "source": [
        "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
        "print('client_id =', client_id)\n",
        "print('# examples =', len(train_fd.get_client(client_id)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "client_id = b'1db830204507458e:THE_TAMING_OF_THE_SHREW_SEBASTIAN'\n",
            "# examples = 483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7r5jfm0V2YH"
      },
      "source": [
        "## Batching client datasets\n",
        "\n",
        "Next we'll go over different methods of iterating over a `fedjax.ClientDataset` as batched examples. All the following methods can be invoked in 2 ways:\n",
        "\n",
        "-   Using a hyperparams object: This is the recommended way in library code. `batch_fn(hparams)`.\n",
        "-   Using keyword arguments: The keyword arguments are used to construct a new hyperparams object, or override an existing one. `batch_fn(batch_size=2)` or `batch_fn(hparams, batch_size=2)` to override `batch_size`.\n",
        "\n",
        "For the most part, we'll use method 2 for this colab, but method 1 is more suitable for writing library code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcGaaGkXf5lz"
      },
      "source": [
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "client_dataset = train_fd.get_client(client_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGyLXbxYDozu"
      },
      "source": [
        "### `batch()` for illustrations\n",
        "\n",
        "Produces preprocessed batches in a fixed sequential order.\n",
        "\n",
        "The final batch may contain fewer than `batch_size` examples. If used directly,\n",
        "that may result in a large number of JIT recompilations. **Therefore we\n",
        "should use `padded_batch()` or `shuffle_repeat_batch()` instead in most scenarios.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opnvtWCODpGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16cfe12-3690-48c3-91a7-58fa9045e97d"
      },
      "source": [
        "batches = list(client_dataset.batch(batch_size=8))\n",
        "batches[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2qFa8HVyar"
      },
      "source": [
        "### `padded_batch()` for evaluation\n",
        "\n",
        "Produces preprocessed padded batches in a fixed sequential order **for evaluation**.\n",
        "\n",
        "When the number of examples in the dataset is not a multiple of `batch_size`,\n",
        "the final batch may be smaller than `batch_size`. This may lead to [a large\n",
        "number of JIT recompilations](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html). This can be circumvented by padding the final\n",
        "batch to a small number of fixed sizes controlled by `num_batch_size_buckets`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRPnF2YOXU6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d1b9e4-0a1a-4f34-a0b4-0ecc830d3362"
      },
      "source": [
        "# use list() to consume generator and store in memory.\n",
        "padded_batches = list(client_dataset.padded_batch(batch_size=8, num_batch_size_buckets=3))\n",
        "print('# batches =', len(padded_batches))\n",
        "padded_batches[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# batches = 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__mask__': array([ True,  True,  True,  True,  True,  True,  True,  True]),\n",
              " 'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67],\n",
              "        [48, 16, 13, 32, 33, 14, 11, 78],\n",
              "        [76, 78, 33, 19, 16, 66, 47,  3],\n",
              "        [16, 27, 67, 23, 26, 47,  3, 27],\n",
              "        [16,  7,  4, 67, 16, 51, 48, 68],\n",
              "        [ 7, 26, 47, 27, 42, 16,  7,  4],\n",
              "        [67, 72, 16, 48, 67, 27, 23, 71],\n",
              "        [67, 65, 29, 79, 76, 51, 74, 12]], dtype=int32),\n",
              " 'y': array([[55, 67, 84, 67, 47,  7, 67, 48],\n",
              "        [16, 13, 32, 33, 14, 11, 78, 76],\n",
              "        [78, 33, 19, 16, 66, 47,  3, 16],\n",
              "        [27, 67, 23, 26, 47,  3, 27, 16],\n",
              "        [ 7,  4, 67, 16, 51, 48, 68,  7],\n",
              "        [26, 47, 27, 42, 16,  7,  4, 67],\n",
              "        [72, 16, 48, 67, 27, 23, 71, 67],\n",
              "        [65, 29, 79, 76, 51, 74, 12, 75]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WzTr7zBXVPj"
      },
      "source": [
        "All batches contain an extra bool feature keyed by `'__mask__'`.\n",
        "`batch['__mask__'][i]` tells us whether the `i`-th example in this batch\n",
        "is an actual example (`batch['__mask__'][i] == True`), or a padding\n",
        "example (`batch['__mask__'][i] == False`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zMXxpp8ZN5F"
      },
      "source": [
        "We repeatedly halve the batch size up to `num_batch_size_buckets - 1` times, until\n",
        "we find the smallest one that is also >= the size of the final batch. Therefore\n",
        "if `batch_size < 2^num_batch_size_buckets`, fewer bucket sizes will be actually\n",
        "used. This will be seen when we look at the final batch that only has 4 examples when the original batch size was 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwqYDivRZR4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77088d4-9c7d-4e01-e223-82910563bca3"
      },
      "source": [
        "padded_batches[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__mask__': array([ True,  True,  True, False]),\n",
              " 'x': array([[16, 16, 16, 16, 16, 16, 16, 16],\n",
              "        [28, 68,  7,  4, 16, 75, 76, 32],\n",
              "        [30, 74, 54, 65,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32),\n",
              " 'y': array([[16, 16, 16, 16, 16, 16, 16, 28],\n",
              "        [68,  7,  4, 16, 75, 76, 32, 30],\n",
              "        [74, 54, 65,  2,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49yb3Bh3Ue4m"
      },
      "source": [
        "### `shuffle_repeat_batch()` for training\n",
        "\n",
        "Produces preprocessed batches in a shuffled and repeated order **for training**.\n",
        "\n",
        "Shuffling is done without replacement, therefore for a dataset of N examples,\n",
        "the first `ceil(N/batch_size)` batches are guarranteed to cover the entire\n",
        "dataset. Unlike `batch()` or `padded_batch()`, batches from\n",
        "`shuffle_repeat_batch()` always contain exactly `batch_size` examples. Also\n",
        "unlike TensorFlow, that holds even when `drop_remainder=False`.\n",
        "\n",
        "By default the iteration stops after the first epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXliT7vawQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0e9a36-6dec-41d0-fb36-8473f9607fc9"
      },
      "source": [
        "print('# batches')\n",
        "len(list(client_dataset.shuffle_repeat_batch(batch_size=8)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# batches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHMy2bUzaPH9"
      },
      "source": [
        "The number of batches produced from the iteration can be controlled by the `(num_epochs, num_steps,\n",
        "drop_remainder)` combination:\n",
        "\n",
        "If both `num_epochs` and `num_steps` are None, the shuffle-repeat process continues forever.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PLFH_zCbfmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e415a00-cf8c-4ee6-cd12-a1235b7a60e0"
      },
      "source": [
        "infinite_bs = client_dataset.shuffle_repeat_batch(\n",
        "    batch_size=8, num_epochs=None, num_steps=None)\n",
        "for i, b in zip(range(6), infinite_bs):\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtdePTEobgEL"
      },
      "source": [
        "If `num_epochs` is set and `num_steps` is None, as few batches as needed to go\n",
        "over the dataset this many passes are produced. Further,\n",
        "\n",
        "-   If `drop_remainder` is False (the default), the final batch is filled with\n",
        "    additionally sampled examples to contain `batch_size` examples.\n",
        "-   If `drop_remainder` is True, the final batch is dropped if it contains fewer\n",
        "    than `batch_size` examples. This may result in examples being skipped when\n",
        "    `num_epochs=1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTUDo9E2blJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8baa67b-74f8-45bd-ba78-70f6e8ce41f7"
      },
      "source": [
        "print('# batches w/ drop_remainder=False')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None))))\n",
        "print('# batches w/ drop_remainder=True')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=None, drop_remainder=True))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# batches w/ drop_remainder=False\n",
            "3\n",
            "# batches w/ drop_remainder=True\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxYReBTkblZN"
      },
      "source": [
        "If `num_steps` is set and `num_steps` is None, exactly this many batches are\n",
        "produced. `drop_remainder` has no effect in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNPvIWdTbnp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4d1d3b-87c2-4174-fce8-e20e001d0a8c"
      },
      "source": [
        "print('# batches w/ num_steps set and drop_remainder=True')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=None, num_steps=3, drop_remainder=True))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# batches w/ num_steps set and drop_remainder=True\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qARHz3mPbn26"
      },
      "source": [
        "If both `num_epochs` and `num_steps` are set, the fewer number of batches\n",
        "between the two conditions are produced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMt9WOaQbpry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9392b235-5113-46da-c750-6df26af16752"
      },
      "source": [
        "print('# batches w/ num_epochs and num_steps set')\n",
        "print(len(list(client_dataset.shuffle_repeat_batch(batch_size=8, num_epochs=1, num_steps=6))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# batches w/ num_epochs and num_steps set\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptjP1zwalp7"
      },
      "source": [
        "If reproducible iteration order is desired, a fixed `seed` can be used. When\n",
        "`seed` is None, repeated iteration over the same object may produce batches in a\n",
        "different order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIZjo5F4bsLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d6f7b9-468f-41d7-9444-ad5a20b9c38a"
      },
      "source": [
        "# Random shuffling.\n",
        "print(list(client_dataset.shuffle_repeat_batch(batch_size=2, seed=None))[0])\n",
        "# Fixed shuffling.\n",
        "print(list(client_dataset.shuffle_repeat_batch(batch_size=2, seed=0))[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'x': array([[30, 74, 54, 65,  0,  0,  0,  0],\n",
            "       [75, 54, 74, 19, 16, 66, 47,  3]], dtype=int32), 'y': array([[74, 54, 65,  2,  0,  0,  0,  0],\n",
            "       [54, 74, 19, 16, 66, 47,  3, 16]], dtype=int32)}\n",
            "{'x': array([[16, 14,  4, 67, 47, 16, 48, 67],\n",
            "       [48, 16, 13, 32, 33, 14, 11, 78]], dtype=int32), 'y': array([[14,  4, 67, 47, 16, 48, 67, 84],\n",
            "       [16, 13, 32, 33, 14, 11, 78, 76]], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybw5LyduIuDC"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "Preprocessing can be done at two levels:\n",
        "\n",
        "1.  The client dataset level with `fedjax.ClientPreprocessor`\n",
        "2.  The batch level with `fedjax.BatchPreprocessor`\n",
        "\n",
        "**Examples of preprocessing possible at either the client dataset level, or\n",
        "the batch level**\n",
        "\n",
        "Such preprocessing is deterministic, and strictly per-example:\n",
        "\n",
        "- Casting a feature from `int8` to `float32`\n",
        "- Adding a new feature derived from existing features\n",
        "- Removing a feature (although the better place to do so is at the dataset\n",
        "  level)\n",
        "\n",
        "A simple rule for deciding where to carry out the preprocessing in this case\n",
        "is the following,\n",
        "\n",
        "- Does this make batching cheaper (e.g. removing features)? If so, do it at\n",
        "  the dataset level.\n",
        "- Otherwise, do it at the batch level.\n",
        "\n",
        "Assuming preprocessing time is linear in the number of examples, preprocessing\n",
        "at the batch level has the benefit of evenly distributing host compute work,\n",
        "which may overlap better with asynchronous JAX compute work on GPU/TPU.\n",
        "\n",
        "**Examples of preprocessing only possible at the batch level**\n",
        "\n",
        "- Data augmentation (e.g. random cropping).\n",
        "- Padding at the batch size dimension.\n",
        "\n",
        "**Examples of preprocessing only possible at the dataset level**\n",
        "\n",
        "- Those that require knowing the client id.\n",
        "- Capping the number of examples.\n",
        "- Altering what it means to be an example: e.g. in certain language model\n",
        "  setups, sentences are concatenated and then split into equal sized chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owvH0JlqgQef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854fdd03-167f-41ce-ff79-7b9b8c6a494e"
      },
      "source": [
        "# Load unpreprocessed data.\n",
        "raw_fd = fedjax.datasets.shakespeare.load_split('train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing cached file '/tmp/.cache/fedjax/shakespeare_train.sqlite'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEmJP73jZZS"
      },
      "source": [
        "### Registering preprocessing\n",
        "\n",
        "We can register extra preprocessing on the `fedjax.FederatedData`\n",
        "using `preprocess_client()` and `preprocess_batch()` for the client dataset\n",
        "level and batch level, respectively. `fedjax.FederatedData` then passes information about preprocessing on to a `fedjax.ClientDataset`.\n",
        "\n",
        "Below, we will walk through an example preprocessing pipeline for Shakespeare\n",
        "that turns text into sequences of integer labels. First, we need a look-up table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CGaM5v6mfDJ"
      },
      "source": [
        "def _build_look_up_table(vocab, num_reserved):\n",
        "  \"\"\"Builds a look-up table from a byte to its integer label.\"\"\"\n",
        "  oov = num_reserved + len(vocab)\n",
        "  vocab_size = oov + 1\n",
        "  table = np.full([256], oov, dtype=np.int32)\n",
        "  for i, c in enumerate(vocab):\n",
        "    table[c] = num_reserved + i\n",
        "  return table, vocab_size\n",
        "\n",
        "\n",
        "# Vocabulary re-used from the Federated Learning for Text Generation tutorial.\n",
        "# https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation\n",
        "TABLE, VOCAB_SIZE = _build_look_up_table(\n",
        "    b'dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r',\n",
        "    num_reserved=3)\n",
        "OOV = VOCAB_SIZE - 1\n",
        "# Reserved labels.\n",
        "PAD = 0\n",
        "BOS = 1\n",
        "EOS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ByT_b9zmFBP"
      },
      "source": [
        "All snippets in a client dataset are first joined into a single sequence (with\n",
        "BOS/EOS added), and then split into pairs of `sequence_length` chunks for\n",
        "language model training. For example, with sequence_length=3, `[b'ABCD', b'E']`\n",
        "becomes\n",
        "\n",
        "```\n",
        "Input sequences:  [[BOS, A, B], [C, D, EOS],   [BOS, E, PAD]]\n",
        "Output seqeunces: [[A, B, C],   [D, EOS, BOS], [E, EOS, PAD]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PISTQyClPdo"
      },
      "source": [
        "def preprocess_client(client_id, examples, sequence_length):\n",
        "  \"\"\"Turns snippets into sequences of integer labels.\"\"\"\n",
        "  del client_id\n",
        "  snippets = examples['snippets']\n",
        "  # Join all snippets into a single label sequence.\n",
        "  joined_length = sum(len(i) + 2 for i in snippets)\n",
        "  joined = np.zeros([joined_length], dtype=np.int32)\n",
        "  offset = 0\n",
        "  for i in snippets:\n",
        "    joined[offset] = BOS\n",
        "    joined[offset + 1:offset + 1 + len(i)] = TABLE[list(i)]\n",
        "    joined[offset + 1 + len(i)] = EOS\n",
        "    offset += len(i) + 2\n",
        "  # Split into input/output sequences of size `sequence_length`.\n",
        "  padded_length = ((joined_length - 1 + sequence_length - 1) //\n",
        "                   sequence_length * sequence_length)\n",
        "  input_labels = np.full([padded_length], PAD, dtype=np.int32)\n",
        "  input_labels[:joined_length - 1] = joined[:-1]\n",
        "  output_labels = np.full([padded_length], PAD, dtype=np.int32)\n",
        "  output_labels[:joined_length - 1] = joined[1:]\n",
        "  return {\n",
        "      'x': input_labels.reshape([-1, sequence_length]),\n",
        "      'y': output_labels.reshape([-1, sequence_length])\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEtuvYvVltSp"
      },
      "source": [
        "Given N input snippets as a bytes NumPy array, the output features will be (M below is possibly different from N):\n",
        "\n",
        "-   `x`: [M, sequence_length] int32 input labels, in the range of [0,\n",
        "    shakespeare.VOCAB_SIZE)\n",
        "-   `y`: [M, sequence_length] int32 output labels, in the range of [0,\n",
        "    shakespeare.VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moZ5YA7sl7Tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0c701d-66b7-4f7f-a396-5c0fa7be875f"
      },
      "source": [
        "client_id = b'105f96df763d4ddf:ALL_S_WELL_THAT_ENDS_WELL_GUIDERIUS_AND_ARVIRAGUS'\n",
        "raw_client_dataset = raw_fd.get_client(client_id)\n",
        "print('Raw unprocessed client dataset')\n",
        "print(raw_client_dataset.all_examples())\n",
        "\n",
        "preprocess = functools.partial(preprocess_client, sequence_length=10)\n",
        "# A new FederatedData object is created when we register new preprocessing.\n",
        "processed_fd = raw_fd.preprocess_client(preprocess)\n",
        "client_dataset = processed_fd.get_client(client_id)\n",
        "print('Preprocessed client dataset')\n",
        "print(client_dataset.all_examples())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw unprocessed client dataset\n",
            "{'snippets': array([b'Re-enter POSTHUMUS, and seconds the Britons; they rescue\\nCYMBELINE, and exeunt. Then re-enter LUCIUS and IACHIMO,\\n                     with IMOGEN\\n'],\n",
            "      dtype=object)}\n",
            "Preprocessed client dataset\n",
            "{'x': array([[ 1, 55, 67, 84, 67, 47,  7, 67, 48, 16],\n",
            "       [13, 32, 33, 14, 11, 78, 76, 78, 33, 19],\n",
            "       [16, 66, 47,  3, 16, 27, 67, 23, 26, 47],\n",
            "       [ 3, 27, 16,  7,  4, 67, 16, 51, 48, 68],\n",
            "       [ 7, 26, 47, 27, 42, 16,  7,  4, 67, 72],\n",
            "       [16, 48, 67, 27, 23, 71, 67, 65, 29, 79],\n",
            "       [76, 51, 74, 12, 75, 54, 74, 19, 16, 66],\n",
            "       [47,  3, 16, 67,  8, 67, 71, 47,  7, 61],\n",
            "       [16, 14,  4, 67, 47, 16, 48, 67, 84, 67],\n",
            "       [47,  7, 67, 48, 16, 12, 78, 29, 75, 78],\n",
            "       [33, 16, 66, 47,  3, 16, 75, 73, 29, 11],\n",
            "       [75, 76, 32, 19, 65, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 28, 68,  7,  4],\n",
            "       [16, 75, 76, 32, 30, 74, 54, 65,  0,  0]], dtype=int32), 'y': array([[55, 67, 84, 67, 47,  7, 67, 48, 16, 13],\n",
            "       [32, 33, 14, 11, 78, 76, 78, 33, 19, 16],\n",
            "       [66, 47,  3, 16, 27, 67, 23, 26, 47,  3],\n",
            "       [27, 16,  7,  4, 67, 16, 51, 48, 68,  7],\n",
            "       [26, 47, 27, 42, 16,  7,  4, 67, 72, 16],\n",
            "       [48, 67, 27, 23, 71, 67, 65, 29, 79, 76],\n",
            "       [51, 74, 12, 75, 54, 74, 19, 16, 66, 47],\n",
            "       [ 3, 16, 67,  8, 67, 71, 47,  7, 61, 16],\n",
            "       [14,  4, 67, 47, 16, 48, 67, 84, 67, 47],\n",
            "       [ 7, 67, 48, 16, 12, 78, 29, 75, 78, 33],\n",
            "       [16, 66, 47,  3, 16, 75, 73, 29, 11, 75],\n",
            "       [76, 32, 19, 65, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "       [16, 16, 16, 16, 16, 28, 68,  7,  4, 16],\n",
            "       [75, 76, 32, 30, 74, 54, 65,  2,  0,  0]], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNY2M7hJgCCV"
      },
      "source": [
        "### `BatchPreprocessor`\n",
        "\n",
        "Preprocessing on a batch of examples can be easily done via a chain of\n",
        "functions. A `fedjax.BatchPreprocessor` holds a chain of preprocessing functions, and applies\n",
        "them in order on batched examples. Each individual preprocessing function\n",
        "operates over multiple examples, instead of just 1 example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0-AE-N-hZ8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d08c809-f807-4002-c9c4-2c39d0323e90"
      },
      "source": [
        "preprocessor = fedjax.BatchPreprocessor([\n",
        "  # Flattens `pixels`.\n",
        "  lambda x: {**x, 'pixels': x['pixels'].reshape([-1, 28 * 28])},\n",
        "  # Introduce `binary_label`.\n",
        "  lambda x: {**x, 'binary_label': x['label'] % 2},\n",
        "])\n",
        "fake_emnist = {\n",
        "  'pixels': np.random.RandomState(0).uniform(size=(2, 28, 28)),\n",
        "  'label': np.random.RandomState(1).randint(10, size=(2,))\n",
        "}\n",
        "preprocessor(fake_emnist)\n",
        "# Produces a dict of [2, 28*28] \"pixels\", [2,] \"label\" and \"binary_label\"."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary_label': array([1, 0]),\n",
              " 'label': array([5, 8]),\n",
              " 'pixels': array([[0.5488135 , 0.71518937, 0.60276338, ..., 0.42690436, 0.84285489,\n",
              "         0.81803331],\n",
              "        [0.10241376, 0.15638335, 0.30419869, ..., 0.34010075, 0.06859683,\n",
              "         0.2289076 ]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A2xxW-IhXUe"
      },
      "source": [
        "Given a `fedjax.BatchPreprocessor`, a new `fedjax.BatchPreprocessor` can be\n",
        "created with an additional preprocessing function appended to the chain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GGDMr3jhudG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b7b89b-a555-4565-dce2-d780fc5441bb"
      },
      "source": [
        "# Continuing from the previous example.\n",
        "new_preprocessor = preprocessor.append(\n",
        "  lambda x: {**x, 'sum_pixels': np.sum(x['pixels'], axis=1)})\n",
        "new_preprocessor(fake_emnist)\n",
        "# Produces a dict of [2, 28*28] \"pixels\", [2,] \"sum_pixels\", \"label\" and\n",
        "# \"binary_label\"."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary_label': array([1, 0]),\n",
              " 'label': array([5, 8]),\n",
              " 'pixels': array([[0.5488135 , 0.71518937, 0.60276338, ..., 0.42690436, 0.84285489,\n",
              "         0.81803331],\n",
              "        [0.10241376, 0.15638335, 0.30419869, ..., 0.34010075, 0.06859683,\n",
              "         0.2289076 ]]),\n",
              " 'sum_pixels': array([388.36415218, 401.91274905])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ERy_YGVhxNR"
      },
      "source": [
        "The main difference of this preprocessor and `fedjax.ClientPreprocessor` is that\n",
        "`fedjax.ClientPreprocessor` also takes `client_id` as input. Because of the\n",
        "identical representation between batched examples and all examples in a client\n",
        "dataset, certain preprocessing can be done with either\n",
        "`fedjax.BatchPreprocessor` or `fedjax.ClientPreprocessor`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UcjabJgB0e"
      },
      "source": [
        "### `ClientPreprocessor`\n",
        "\n",
        "A chain of preprocessing functions on all examples of a client dataset.\n",
        "\n",
        "This is very similar to `fedjax.BatchPreprocessor`, with the main difference\n",
        "being that `ClientPreprocessor` also takes `client_id` as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdHnE6p8AHoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea402ae4-6445-4e0e-c9d1-cda7d2d0b2b5"
      },
      "source": [
        "preprocessor = fedjax.ClientPreprocessor([\n",
        "  # Adds `client_id_length`.\n",
        "  lambda cid, x: {**x, 'client_id_length': np.ones_like(x['label']) * len(cid)}\n",
        "])\n",
        "fake_emnist = {\n",
        "  'label': np.random.RandomState(0).randint(10, size=(2,))\n",
        "}\n",
        "client_id = b'123456'\n",
        "preprocessor(client_id, fake_emnist)\n",
        "# Produces a dict of [2,] \"label\" and \"client_id_length\"."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_id_length': array([6, 6]), 'label': array([5, 0])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS8DIlotEVjz"
      },
      "source": [
        "## Creating custom federated datasets\n",
        "\n",
        "In many scenarios, it is desirable to create a custom federated dataset. FedJAX provides `fedjax.InMemoryDataset` to create small custom datasets. `fedjax.InMemoryDataset` takes a dictionary of numpy examples keyed by client id and creates a `fedjax.FederatedData` that is compatible with the rest of the library. We illustrate with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsKFk9eWE8HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c84033c-41fb-4993-fac7-35ea3107dd49"
      },
      "source": [
        "# Obtain MNIST dataset from tensorflow and convert to numpy format.\n",
        "import tensorflow_datasets as tfds\n",
        "(ds_train, ds_test) = tfds.load('mnist',\n",
        "                                split=['train', 'test'],\n",
        "                                shuffle_files=True,\n",
        "                                as_supervised=True,\n",
        "                                with_info=False)\n",
        "features, labels = list(ds_train.batch(60000).as_numpy_iterator())[0]\n",
        "print('features shape', features.shape)\n",
        "print('labels shape', labels.shape)\n",
        "\n",
        "# Randomly split dataset into 100 clients and load them to a dictionary.\n",
        "indices = np.random.randint(100, size=60000)\n",
        "client_id_to_dataset_mapping = {}\n",
        "for i in range(100):\n",
        "  client_id_to_dataset_mapping[i] = {'x': features[indices==i, :, : , :],\n",
        "                                     'y': labels[indices==i]}\n",
        "\n",
        "# Create fedjax.InMemoryDataset.\n",
        "iid_mnist_federated_data = fedjax.InMemoryFederatedData(\n",
        "    client_id_to_dataset_mapping)\n",
        "\n",
        "print('number of clients in iid_mnist_data',\n",
        "      iid_mnist_federated_data.num_clients())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features shape (60000, 28, 28, 1)\n",
            "labels shape (60000,)\n",
            "number of clients in iid_mnist_data 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV3azKfTHoH2"
      },
      "source": [
        "## Recap\n",
        "\n",
        "In this tutorial, we have covered the following:\n",
        "\n",
        "1. Using `fedjax.FederatedData`.\n",
        "2. Different ways of batching client datasets.\n",
        "3. Different ways of processing client datasets.\n",
        "4. Creating small custom federated datasets. "
      ]
    }
  ]
}